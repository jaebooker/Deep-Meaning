{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdb = pd.read_csv(\"Shakespeare-plays/Shakespeare_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['comedy','tragedy','other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_the_plays():\n",
    "    new_play = \"Henry IV\"\n",
    "    play_array = []\n",
    "    for i in sdb['Play']:\n",
    "        if i != new_play:\n",
    "            play_array.append(new_play)\n",
    "            new_play = i\n",
    "    return play_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plays = all_the_plays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(play_name):\n",
    "    play = sdb[sdb['Play']==play_name]\n",
    "    w = play['PlayerLine']\n",
    "    text = \"\"\n",
    "    for i in w:\n",
    "        text += i\n",
    "        text += \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_training = []\n",
    "tragedy_training = []\n",
    "history_training = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_text():\n",
    "    comedy_training.append(get_text(\"Alls well that ends well\"))\n",
    "    comedy_training.append(get_text(\"As you like it\"))\n",
    "    comedy_training.append(get_text(\"Loves Labours Lost\"))\n",
    "    comedy_training.append(get_text(\"Measure for measure\"))\n",
    "    comedy_training.append(get_text(\"Merry Wives of Windsor\"))\n",
    "    comedy_training.append(get_text(\"A Midsummer nights dream\"))\n",
    "    comedy_training.append(get_text(\"Taming of the Shrew\"))\n",
    "    comedy_training.append(get_text(\"The Tempest\"))\n",
    "    comedy_training.append(get_text(\"Two Gentlemen of Verona\"))\n",
    "    comedy_training.append(get_text(\"A Winters Tale\"))\n",
    "    tragedy_training.append(get_text(\"Antony and Cleopatra\"))\n",
    "    tragedy_training.append(get_text(\"Coriolanus\"))\n",
    "    tragedy_training.append(get_text(\"Hamlet\"))\n",
    "    tragedy_training.append(get_text(\"Julius Caesar\"))\n",
    "    tragedy_training.append(get_text(\"macbeth\"))\n",
    "    tragedy_training.append(get_text(\"Othello\"))\n",
    "    tragedy_training.append(get_text(\"Timon of Athens\"))\n",
    "    tragedy_training.append(get_text(\"Titus Andronicus\"))\n",
    "    history_training.append(get_text(\"Henry IV\"))\n",
    "    history_training.append(get_text(\"Henry VI Part 1\"))\n",
    "    history_training.append(get_text(\"Henry VI Part 3\"))\n",
    "    history_training.append(get_text(\"Henry VIII\"))\n",
    "    history_training.append(get_text(\"King John\"))\n",
    "    history_training.append(get_text(\"Richard II\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_testing = []\n",
    "tragedy_testing = []\n",
    "history_testing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_text():\n",
    "    comedy_testing.append(get_text(\"A Comedy of Errors\"))\n",
    "    comedy_testing.append(get_text(\"Merchant of Venice\"))\n",
    "    comedy_testing.append(get_text(\"Much Ado about nothing\"))\n",
    "    comedy_testing.append(get_text(\"Twelfth Night\"))\n",
    "    tragedy_testing.append(get_text(\"Cymbeline\"))\n",
    "    tragedy_testing.append(get_text(\"King Lear\"))\n",
    "    tragedy_testing.append(get_text(\"Romeo and Juliet\"))\n",
    "    tragedy_testing.append(get_text(\"Troilus and Cressida\"))\n",
    "    history_testing.append(get_text(\"Henry V\"))\n",
    "    history_testing.append(get_text(\"Henry VI Part 3\"))\n",
    "    history_testing.append(get_text(\"Pericles\"))\n",
    "    history_testing.append(get_text(\"Richard III\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_training_text()\n",
    "get_testing_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shakes_text_array(text):\n",
    "    w = re.split(\"\\W*[^\\'\\w+\\']\", text)\n",
    "    text_array = []\n",
    "    for i in w:\n",
    "        text_array.append([i])\n",
    "    return text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(max_sequence_len, total_words):\n",
    "#     input_len = max_sequence_len - 1\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     # Add Input Embedding Layer\n",
    "#     model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "#     # Add Hidden Layer 1 - LSTM Layer\n",
    "#     model.add(LSTM(512))\n",
    "#     model.add(Dropout(0.4))\n",
    "    \n",
    "#     # Add Output Layer\n",
    "#     model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = create_model(max_sequence_len, total_words)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(words):\n",
    "    count_words = Counter(words)\n",
    "    total_words = len(words)\n",
    "    sorted_words = count_words.most_common(total_words)\n",
    "    return sorted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_encoding(words):\n",
    "    words_split = words.split('\\n')\n",
    "    words_int = []\n",
    "    for play in words_split:\n",
    "        p = [words_int[w] for w in play.split()]\n",
    "        words_int.append(p)\n",
    "    return words_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(labels_split):\n",
    "    encoded_labels = []\n",
    "    for l in labels_split:\n",
    "        if l == 'comedy':\n",
    "            encoded_labels.append(0)\n",
    "        elif l == 'tragedy':\n",
    "            encoded_labels.append(1)\n",
    "        else:\n",
    "            encoded_labels.append(2)\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(encoded_labels) = encoding(labels_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(plays_int, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.zeros((len(plays_int), seq_length), dtype = int)\n",
    "    \n",
    "    for i, p in enumerate(plays_int):\n",
    "        play_len = len(p)\n",
    "        \n",
    "        if play_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length-play_len))\n",
    "            new = zeroes+p\n",
    "        elif play_len > seq_length:\n",
    "            new = play[0:seq_length]\n",
    "        \n",
    "        features[i,:] = np.array(new)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
